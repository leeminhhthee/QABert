import streamlit as st
from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline

# ÄÆ°á»ng dáº«n tá»›i thÆ° má»¥c chá»©a model Ä‘Ã£ fine-tune
save_dir = "bert-finetuned-qa"

# Load model vÃ  tokenizer
model = AutoModelForQuestionAnswering.from_pretrained(save_dir)
tokenizer = AutoTokenizer.from_pretrained(save_dir)

# Táº¡o pipeline
question_answerer = pipeline("question-answering", model=model, tokenizer=tokenizer)

# UI Streamlit
st.title("ğŸ¤– Question Answering System with BERT")

context = st.text_area("ğŸ“š Enter paragraph (context):", height=200)
question = st.text_input("â“ Enter question:")

if st.button("Answer"):
    if context.strip() == "" or question.strip() == "":
        st.warning("Please enter both the paragraph and the question.!")
    else:
        with st.spinner("Thinking..."):
            result = question_answerer(question=question, context=context)
            st.success(f"âœ… Answer: {result['answer']}")
            st.info(f"ğŸ“Š Confidence: {result['score']:.4f}")
